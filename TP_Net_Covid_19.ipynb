{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python_defaultSpec_1597595321060",
   "display_name": "Python 3.7.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "from keras.models import Model\n",
    "import csv\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_image(root_path, height, width, classes):\n",
    "    label_map = {'BacterialPneumonia': 1,\n",
    "                 'COVID-19': 0,\n",
    "                 'Normal': 2,\n",
    "                 'ViralPneumonia': 1}\n",
    "    data, labels = [], []\n",
    "    dirs = os.listdir(root_path)\n",
    "    if '.DS_Store' in dirs:\n",
    "        dirs.remove('.DS_Store')\n",
    "    for d in dirs:\n",
    "        path = os.path.join(root_path, d)\n",
    "        img_count = os.listdir(path)\n",
    "        for img in img_count:\n",
    "            try: \n",
    "                img_path = os.path.join(path, img)\n",
    "                image = cv2.imread(img_path)\n",
    "                image_from_array = Image.fromarray(image, 'RGB')\n",
    "                size_image = image_from_array.resize((width, height))\n",
    "                data.append(np.array(size_image))\n",
    "                labels.append(label_map[d])\n",
    "            except AttributeError:\n",
    "                print(\" \")\n",
    "    \n",
    "    Cells = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    s = np.arange(Cells.shape[0])\n",
    "    np.random.seed(classes)\n",
    "    np.random.shuffle(s)\n",
    "    Cells = Cells[s]\n",
    "    labels = labels[s]\n",
    "    \n",
    "    X = Cells.astype('float32')/255\n",
    "    y = to_categorical(labels, classes)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def data_processing(data_path, height, width, classes):\n",
    "    train_path = os.path.join(data_path, 'NonAugmentedTrain')\n",
    "    val_path = os.path.join(data_path, 'ValData')\n",
    "    X_train, y_train = load_image(train_path, height, width, classes)\n",
    "    X_val, y_val = load_image(val_path, height, width, classes)\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_flops(model):\n",
    "    run_meta = tf.RunMetadata()\n",
    "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "    # We use the Keras session graph in the call to the profiler.\n",
    "    flops = tf.profiler.profile(graph=bk.get_session().graph,\n",
    "                                run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "\n",
    "def piecewise5(X):\n",
    "    return bk.switch(X < -0.6, (0.01 * X ),\n",
    "                     bk.switch(X < -0.2, (0.2 * X ),\n",
    "                               bk.switch(X < 0.2, (1 * X ),\n",
    "                                         bk.switch(X < 0.6, (1.5 * X ),\n",
    "                                                   bk.switch(X < 5, (3 * X ), (3 * X )))))) \n",
    "\n",
    "\n",
    "class CustomNetwork(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(1, 16, kernel_size=1, padding=0)\n",
    "        self.conv_2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.avgpool_1 = nn.AdaptiveAvgPool2d((16, 16))\n",
    "        self.maxpool_1 = nn.MaxPool2d(kernel_size=2, padding=0)\n",
    "        self.dropout_1 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(32, 32, kernel_size=1, padding=0)\n",
    "        self.conv_4 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.maxpool_2 = nn.MaxPool2d(kernel_size=2, padding=0)\n",
    "        self.dropout_2 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.avgpool_2 = nn.AvgPool2d(kernel_size=4, padding=0)\n",
    "        self.dropout_3 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.avgpool_3 = nn.AvgPool2d(kernel_size=2, padding=0)\n",
    "        self.dropout_4 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.fc = nn.Linear(12304, classes)\n",
    "        \n",
    "    def forward(self, input_img):\n",
    "        tower_1 = F.elu(self.conv_1(input_img))\n",
    "        tower_x = F.elu(self.conv_2(tower_1))\n",
    "        block1_output = self.avgpool_1(tower_1)\n",
    "        \n",
    "        tower_y = self.maxpool_1(tower_x)\n",
    "        tower_y = self.dropout_1(tower_y)\n",
    "        tower_z = F.elu(self.conv_3(tower_y))\n",
    "        tower_a = F.elu(self.conv_4(tower_z))\n",
    "        tower_a = self.maxpool_2(tower_a)\n",
    "        tower_a = self.dropout_2(tower_a)\n",
    "        \n",
    "        tower_2 = self.avgpool_2(tower_x)\n",
    "        tower_2 = self.dropout_3(tower_2)\n",
    "        \n",
    "        tower_3 = self.avgpool_3(tower_z)\n",
    "        tower_3 = self.dropout_4(tower_3)\n",
    "        \n",
    "        output = torch.cat((tower_a, tower_2, tower_3), 1)\n",
    "        output = torch.flatten(output)\n",
    "\n",
    "        out1 = torch.cat((output, block1_output), 1)\n",
    "        \n",
    "        out = F.softmax(self.fc(out1), dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(400, 300, 3)\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 69120000], m2: [12304 x 4] at ..\\aten\\src\\TH/generic/THTensorMath.cpp:41",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0de607f8fbf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a353117465c9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_img)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m#out1 = torch.cat((output, block1_output), 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 69120000], m2: [12304 x 4] at ..\\aten\\src\\TH/generic/THTensorMath.cpp:41"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    height = 400\n",
    "    width = 300\n",
    "    channels = 3\n",
    "    classes = 4\n",
    "    ratio_train = 0.8\n",
    "    ratio_val = 0.2\n",
    "    save_path = './training_info.csv'\n",
    "    pre_trained_model_path = ''\n",
    "    model_save_path = './test2_model.h5'\n",
    "    data_path = './covid19-detection-xray-dataset'\n",
    "    \n",
    "    if ratio_train + ratio_val > 1:\n",
    "        print('Train/eval splitting failed')\n",
    "        exit(0)\n",
    "    X_train, y_train, X_val, y_val = data_processing(data_path,\n",
    "                                                     height, \n",
    "                                                     width,  \n",
    "                                                     classes)\n",
    "\n",
    "    network = CustomNetwork(classes)    \n",
    "    \n",
    "    optimizer = optim.SGD(network.parameters(), lr=0.001)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    X_train_t = torch.Tensor(X_train)\n",
    "    y_train_t = torch.Tensor(y_train)\n",
    "    X_val_t = torch.Tensor(X_val)\n",
    "    y_val_t = torch.Tensor(y_val)\n",
    "\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    for epoch in range(epochs):\n",
    "        print(input_shape)\n",
    "        for i in range(0, batch_size): \n",
    "            \n",
    "            batch_X = X_train_t[i:i + batch_size].view(-1, 1, height, width)\n",
    "            batch_y = y_train_t[i:i + batch_size]\n",
    "        \n",
    "            network.zero_grad()\n",
    "        \n",
    "            outputs = network.forward(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "\n",
    "    print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "        \n",
    "    # get_custom_objects().update({'piecewise5': Activation(piecewise5)})\n",
    "    # input_shape = X_train.shape[1:]\n",
    "\n",
    "    # sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
    "    # model = custom_network(height, width, classes, pre_trained_model_path)\n",
    "    \n",
    "    # model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "    #               optimizer='adam',\n",
    "    #               metrics=['accuracy'])\n",
    "    \n",
    "    # epochs = 5\n",
    "    # hist1 = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_val, y_val))\n",
    "    # model.save(model_save_path)  # should end with .h5 or .hdf5\n",
    "    \n",
    "    # history = hist1.history\n",
    "    \n",
    "    # score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    # score2 = model.evaluate(X_train, y_train, verbose=0)\n",
    "    # print('Test loss:', score[0])\n",
    "    # print('Test accuracy:', score[1])\n",
    "    # print('Training loss:', score2[0])\n",
    "    # print('Training accuracy:', score2[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}