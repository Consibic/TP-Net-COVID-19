{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit6e94967ef65f4fa3a3a449757b219536",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "from keras.models import Model\n",
    "import csv\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_image(root_path, height, width, classes):\n",
    "    data, labels = [], []\n",
    "    dirs = os.listdir(root_path)\n",
    "    if '.DS_Store' in dirs:\n",
    "        dirs.remove('.DS_Store')\n",
    "    for d in dirs:\n",
    "        path = os.path.join(root_path, d)\n",
    "        img_count = os.listdir(path)\n",
    "        for img in img_count:\n",
    "            try: \n",
    "                img_path = os.path.join(path, img)\n",
    "                image = cv2.imread(img_path)\n",
    "                image_from_array = Image.fromarray(image, 'RGB')\n",
    "                size_image = image_from_array.resize((height, width))\n",
    "                data.append(np.array(size_image))\n",
    "                labels.append(d)\n",
    "            except AttributeError:\n",
    "                print(\" \")\n",
    "    \n",
    "    Cells = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    s = np.arange(Cells.shape[0])\n",
    "    np.random.seed(classes)\n",
    "    np.random.shuffle(s)\n",
    "    Cells = Cells[s]\n",
    "    labels = labels[s]\n",
    "    \n",
    "    X = Cells.astype('float32')/255\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(labels)\n",
    "\n",
    "    y = to_categorical(y, classes)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def data_processing(data_path, height, width, classes):\n",
    "    train_path = os.path.join(data_path, 'NonAugmentedTrain')\n",
    "    val_path = os.path.join(data_path, 'ValData')\n",
    "    X_train, y_train = load_image(train_path, height, width, classes)\n",
    "    X_val, y_val = load_image(val_path, height, width, classes)\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3351: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nModel: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            (None, 400, 300, 3)  0                                            \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 400, 300, 64) 1792        input_4[0][0]                    \n__________________________________________________________________________________________________\nmax_pooling2d_5 (MaxPooling2D)  (None, 200, 150, 64) 0           conv2d_9[0][0]                   \n__________________________________________________________________________________________________\ndropout_9 (Dropout)             (None, 200, 150, 64) 0           max_pooling2d_5[0][0]            \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 200, 150, 128 73856       dropout_9[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_6 (MaxPooling2D)  (None, 100, 75, 128) 0           conv2d_10[0][0]                  \n__________________________________________________________________________________________________\ndropout_10 (Dropout)            (None, 100, 75, 128) 0           max_pooling2d_6[0][0]            \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 100, 75, 64)  73792       dropout_10[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_7 (MaxPooling2D)  (None, 50, 38, 64)   0           conv2d_11[0][0]                  \n__________________________________________________________________________________________________\ndropout_11 (Dropout)            (None, 50, 38, 64)   0           max_pooling2d_7[0][0]            \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 50, 38, 128)  73856       dropout_11[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_8 (MaxPooling2D)  (None, 25, 19, 128)  0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\ndropout_12 (Dropout)            (None, 25, 19, 128)  0           max_pooling2d_8[0][0]            \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 25, 19, 64)   73792       dropout_12[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_9 (MaxPooling2D)  (None, 13, 10, 64)   0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\ndropout_13 (Dropout)            (None, 13, 10, 64)   0           max_pooling2d_9[0][0]            \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 13, 10, 128)  73856       dropout_13[0][0]                 \n__________________________________________________________________________________________________\nglobal_average_pooling2d_3 (Glo (None, 64)           0           conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nglobal_average_pooling2d_4 (Glo (None, 128)          0           conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling2d_5 (Glo (None, 64)           0           conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling2d_6 (Glo (None, 128)          0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling2d_7 (Glo (None, 64)           0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling2d_8 (Glo (None, 128)          0           conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 576)          0           global_average_pooling2d_3[0][0] \n                                                                 global_average_pooling2d_4[0][0] \n                                                                 global_average_pooling2d_5[0][0] \n                                                                 global_average_pooling2d_6[0][0] \n                                                                 global_average_pooling2d_7[0][0] \n                                                                 global_average_pooling2d_8[0][0] \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 64)           36928       concatenate_5[0][0]              \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 4)            260         dense_3[0][0]                    \n==================================================================================================\nTotal params: 408,132\nTrainable params: 408,132\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n"
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_4 to have shape (400, 300, 3) but got array with shape (300, 400, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a1bcbc2874fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mhist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# should end with .h5 or .hdf5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_4 to have shape (400, 300, 3) but got array with shape (300, 400, 3)"
     ]
    }
   ],
   "source": [
    "from GC_NET import get_flops, piecewise5, custom_network\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    height = 400\n",
    "    width = 300\n",
    "    channels = 3\n",
    "    classes = 4\n",
    "    ratio_train = 0.8\n",
    "    ratio_val = 0.2\n",
    "    save_path = './training_info.csv'\n",
    "    pre_trained_model_path = ''\n",
    "    model_save_path = './test2_model.h5'\n",
    "    data_path = './covid19-detection-xray-dataset'\n",
    "    \n",
    "    if ratio_train + ratio_val > 1:\n",
    "        print('Train/eval splitting failed')\n",
    "        exit(0)\n",
    "    X_train, y_train, X_val, y_val = data_processing(data_path,\n",
    "                                                     height, \n",
    "                                                     width,  \n",
    "                                                     classes)\n",
    "        \n",
    "    get_custom_objects().update({'piecewise5': Activation(piecewise5)})\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
    "    model = custom_network(height, width, classes, pre_trained_model_path)\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    epochs = 5\n",
    "    hist1 = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_val, y_val))\n",
    "    model.save(model_save_path)  # should end with .h5 or .hdf5\n",
    "    \n",
    "    history = hist1.history\n",
    "    \n",
    "    score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    score2 = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('Training loss:', score2[0])\n",
    "    print('Training accuracy:', score2[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}