{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid19_runner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m2UXxLgrKhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61eba508-4ca2-470e-95c3-41c16671aa1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4P173M-iHID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f63a4a1-daba-4adf-b55f-d55caa58e242"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNgr3iOhivfO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f74daecc-a60e-4a69-87fa-c4724d77f4cc"
      },
      "source": [
        "# Libraries \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "from keras.models import Model\n",
        "import csv\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def load_image(root_path, height, width, classes):\n",
        "    label_map = {'BacterialPneumonia': 1,\n",
        "                 'COVID-19': 0,\n",
        "                 'Normal': 2,\n",
        "                 'ViralPneumonia': 1}\n",
        "    data, labels = [], []\n",
        "    dirs = os.listdir(root_path)\n",
        "    \n",
        "    for d in dirs:\n",
        "        print(d)\n",
        "        path = os.path.join(root_path, d)\n",
        "        img_count = os.listdir(path)\n",
        "        for img in img_count:\n",
        "            try: \n",
        "                img_path = os.path.join(path, img)\n",
        "                image = cv2.imread(img_path)\n",
        "                image_from_array = Image.fromarray(image, 'RGB')\n",
        "                size_image = image_from_array.resize((width, height))\n",
        "                data.append(np.array(size_image))\n",
        "                labels.append(label_map[d])\n",
        "            except AttributeError:\n",
        "                print(\" \")\n",
        "    \n",
        "    Cells = np.array(data)\n",
        "    labels = np.array(labels)\n",
        "    \n",
        "    s = np.arange(Cells.shape[0])\n",
        "    np.random.seed(classes)\n",
        "    np.random.shuffle(s)\n",
        "    Cells = Cells[s]\n",
        "    labels = labels[s]\n",
        "    \n",
        "    X = Cells.astype('float32')/255\n",
        "    y = to_categorical(labels, classes)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def data_processing(data_path, height, width, classes):\n",
        "    train_path = os.path.join(data_path, 'NonAugmentedTrain')\n",
        "    val_path = os.path.join(data_path, 'ValData')\n",
        "    X_train, y_train = load_image(train_path, height, width, classes)\n",
        "    X_val, y_val = load_image(val_path, height, width, classes)\n",
        "    return X_train, y_train, X_val, y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4jJ3ET2kDSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras import backend as bk\n",
        "from keras import optimizers\n",
        "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras import initializers, regularizers\n",
        "import tensorflow as tf\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.models import load_model\n",
        "\n",
        "class Piecewise5(Activation):\n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(Piecewise5, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'Piecewise5'\n",
        "\n",
        "def get_flops(model):\n",
        "    run_meta = tf.RunMetadata()\n",
        "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
        "\n",
        "    # We use the Keras session graph in the call to the profiler.\n",
        "    flops = tf.profiler.profile(graph=bk.get_session().graph,\n",
        "                                run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "    return flops.total_float_ops\n",
        "\n",
        "\n",
        "def piecewise5(X):\n",
        "    return bk.switch(X < -0.6, (0.01 * X ),\n",
        "                     bk.switch(X < -0.2, (0.2 * X ),\n",
        "                               bk.switch(X < 0.2, (1 * X ),\n",
        "                                         bk.switch(X < 0.6, (1.5 * X ),\n",
        "                                                   bk.switch(X < 5, (3 * X ), (3 * X )))))) \n",
        "\n",
        "\n",
        "def custom_network(height, width, channels, classes, pre_trained=''):\n",
        "    weight_decay = 0.0001\n",
        "    input_img = Input(shape=(height, width, channels))\n",
        "    if pre_trained != '':\n",
        "        base_model = load_model(pre_trained)\n",
        "        num_layers = len(base_model.layers)\n",
        "        base_output = base_model.get_layer(index=num_layers-2).output\n",
        "        out = Dense(classes, activation='softmax')(base_output)\n",
        "        model = Model(inputs=base_model.input, outputs=out)\n",
        "    else:\n",
        "        tower_1 = Conv2D(16, (1, 1), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(input_img)\n",
        "        tower_x = Conv2D(32, (3, 3), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_1)\n",
        "        block1_output = GlobalAveragePooling2D()(tower_1)\n",
        "        tower_y = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_x)\n",
        "        tower_y = Dropout(0.1)(tower_y)\n",
        "        tower_z = Conv2D(32, (1, 1), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_y)\n",
        "        tower_a = Conv2D(32, (3, 3), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_z)\n",
        "        tower_a = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_a)\n",
        "        tower_a = Dropout(0.1)(tower_a)\n",
        "\n",
        "        tower_2 = AveragePooling2D(pool_size=(4, 4), padding='same')(tower_x)\n",
        "        tower_2 = Dropout(0.1)(tower_2)\n",
        "\n",
        "        tower_3 = AveragePooling2D(pool_size=(2, 2), padding='same')(tower_z)\n",
        "        tower_3 = Dropout(0.1)(tower_3)\n",
        "        \n",
        "        output = keras.layers.concatenate([tower_a, tower_2, tower_3], axis=1)\n",
        "        # output = Flatten()(output)\n",
        "        # out1 = keras.layers.concatenate([output, block1_output], axis=1)\n",
        "        \n",
        "        tower_1_2 = Conv2D(16, (1, 1), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(output)\n",
        "        tower_x_2 = Conv2D(32, (3, 3), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_1_2)\n",
        "        # block1_output_2 = GlobalAveragePooling2D()(tower_1_2)\n",
        "        tower_y_2 = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_x_2)\n",
        "        tower_y_2 = Dropout(0.1)(tower_y_2)\n",
        "        tower_z_2 = Conv2D(32, (1, 1), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_y_2)\n",
        "        tower_a_2 = Conv2D(32, (3, 3), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_z_2)\n",
        "        tower_a_2 = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_a_2)\n",
        "        tower_a_2 = Dropout(0.1)(tower_a_2)\n",
        "\n",
        "        tower_2_2 = AveragePooling2D(pool_size=(4, 4), padding='same')(tower_x_2)\n",
        "        tower_2_2 = Dropout(0.1)(tower_2_2)\n",
        "\n",
        "        tower_3_2 = AveragePooling2D(pool_size=(2, 2), padding='same')(tower_z_2)\n",
        "        tower_3_2 = Dropout(0.1)(tower_3_2)\n",
        "\n",
        "        output_2 = keras.layers.concatenate([tower_a_2, tower_2_2, tower_3_2], axis=1)\n",
        "        output_2 = Flatten()(output_2)\n",
        "        out1_2 = keras.layers.concatenate([output_2, block1_output], axis=1)\n",
        "\n",
        "        out = Dense(classes, activation='softmax')(out1_2)\n",
        "\n",
        "        model = Model(inputs=input_img, outputs=out)\n",
        "\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgGc6UC_oL4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "312f0cef-7d15-4169-bc40-d7b7174f3acf"
      },
      "source": [
        "height = 400\n",
        "width = 300\n",
        "channels = 3\n",
        "classes = 3\n",
        "ratio_train = 0.8\n",
        "ratio_val = 0.2\n",
        "save_path = '/content/drive/My Drive/Colab Notebooks/training_info.xlsx'\n",
        "pre_trained_model_path = ''\n",
        "model_save_path = '/content/drive/My Drive/Colab Notebooks/test_model.h5'\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/covid19-detection-xray-dataset'\n",
        "    \n",
        "if ratio_train + ratio_val > 1:\n",
        "    print('Train/eval splitting failed')\n",
        "    exit(0)\n",
        "X_train, y_train, X_val, y_val = data_processing(data_path,\n",
        "                                                     height, \n",
        "                                                     width,  \n",
        "                                                     classes)\n",
        "        \n",
        "get_custom_objects().update({'piecewise5': Piecewise5(piecewise5)})\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
        "model = custom_network(height, width, channels, classes, pre_trained_model_path)\n",
        "    \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "epochs = 25\n",
        "hist1 = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_val, y_val))\n",
        "model.save(model_save_path)  # should end with .h5 or .hdf5\n",
        "    \n",
        "history = hist1.history\n",
        "    \n",
        "score = model.evaluate(X_val, y_val, verbose=0)\n",
        "score2 = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('Training loss:', score2[0])\n",
        "print('Training accuracy:', score2[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ViralPneumonia\n",
            "COVID-19\n",
            "Normal\n",
            "BacterialPneumonia\n",
            "BacterialPneumonia\n",
            "COVID-19\n",
            "Normal\n",
            "ViralPneumonia\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 400, 300, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 400, 300, 16) 64          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 400, 300, 32) 4640        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 200, 150, 32) 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 150, 32) 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 200, 150, 32) 1056        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 200, 150, 32) 9248        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 100, 75, 32)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 100, 75, 32)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 100, 75, 32)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100, 75, 32)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 100, 75, 32)  0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 100, 75, 32)  0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 300, 75, 32)  0           dropout_2[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 300, 75, 16)  528         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 300, 75, 32)  4640        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 150, 38, 32)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 150, 38, 32)  0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 150, 38, 32)  1056        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 150, 38, 32)  9248        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 75, 19, 32)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 75, 19, 32)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 75, 19, 32)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 75, 19, 32)   0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 75, 19, 32)   0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 75, 19, 32)   0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 225, 19, 32)  0           dropout_6[0][0]                  \n",
            "                                                                 dropout_7[0][0]                  \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 136800)       0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 16)           0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 136816)       0           flatten_1[0][0]                  \n",
            "                                                                 global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3)            410451      concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 440,931\n",
            "Trainable params: 440,931\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 2002 samples, validate on 988 samples\n",
            "Epoch 1/25\n",
            "2002/2002 [==============================] - 44s 22ms/step - loss: 1.7163 - accuracy: 0.7178 - val_loss: 0.4052 - val_accuracy: 0.8381\n",
            "Epoch 2/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.3130 - accuracy: 0.8821 - val_loss: 0.4434 - val_accuracy: 0.8259\n",
            "Epoch 3/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.2485 - accuracy: 0.9076 - val_loss: 0.2139 - val_accuracy: 0.9170\n",
            "Epoch 4/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.2362 - accuracy: 0.9066 - val_loss: 0.2105 - val_accuracy: 0.9221\n",
            "Epoch 5/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.1668 - accuracy: 0.9371 - val_loss: 0.2279 - val_accuracy: 0.9180\n",
            "Epoch 6/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.1436 - accuracy: 0.9491 - val_loss: 0.2111 - val_accuracy: 0.9281\n",
            "Epoch 7/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.1288 - accuracy: 0.9476 - val_loss: 0.2242 - val_accuracy: 0.9190\n",
            "Epoch 8/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.1014 - accuracy: 0.9680 - val_loss: 0.3032 - val_accuracy: 0.8988\n",
            "Epoch 9/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.1594 - accuracy: 0.9500 - val_loss: 0.2011 - val_accuracy: 0.9170\n",
            "Epoch 10/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0733 - accuracy: 0.9770 - val_loss: 0.2035 - val_accuracy: 0.9291\n",
            "Epoch 11/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0665 - accuracy: 0.9785 - val_loss: 0.2545 - val_accuracy: 0.9180\n",
            "Epoch 12/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0744 - accuracy: 0.9755 - val_loss: 0.2435 - val_accuracy: 0.9190\n",
            "Epoch 13/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0717 - accuracy: 0.9710 - val_loss: 0.2153 - val_accuracy: 0.9281\n",
            "Epoch 14/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0848 - accuracy: 0.9700 - val_loss: 0.2085 - val_accuracy: 0.9322\n",
            "Epoch 15/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 0.2412 - val_accuracy: 0.9332\n",
            "Epoch 16/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0396 - accuracy: 0.9845 - val_loss: 0.2499 - val_accuracy: 0.9221\n",
            "Epoch 17/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0538 - accuracy: 0.9805 - val_loss: 0.2594 - val_accuracy: 0.9322\n",
            "Epoch 18/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0416 - accuracy: 0.9850 - val_loss: 0.2905 - val_accuracy: 0.9231\n",
            "Epoch 19/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0462 - accuracy: 0.9845 - val_loss: 0.2972 - val_accuracy: 0.9200\n",
            "Epoch 20/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0274 - accuracy: 0.9885 - val_loss: 0.2511 - val_accuracy: 0.9322\n",
            "Epoch 21/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0156 - accuracy: 0.9930 - val_loss: 0.2480 - val_accuracy: 0.9332\n",
            "Epoch 22/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 0.2427 - val_accuracy: 0.9342\n",
            "Epoch 23/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0160 - accuracy: 0.9930 - val_loss: 0.2456 - val_accuracy: 0.9332\n",
            "Epoch 24/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 0.2707 - val_accuracy: 0.9332\n",
            "Epoch 25/25\n",
            "2002/2002 [==============================] - 34s 17ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.2979 - val_accuracy: 0.9342\n",
            "Test loss: 0.2979235730250837\n",
            "Test accuracy: 0.9342105388641357\n",
            "Training loss: 0.002288646513612924\n",
            "Training accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}