{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid19_runner_gcnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m2UXxLgrKhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2b2007ca-701c-41f1-8aa7-5ccdb8d76b7b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4P173M-iHID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3f6ad37-72ea-4b5a-8806-8c875fdbdeee"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNgr3iOhivfO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddc72669-3aa6-4de3-c2ad-7ee9407d9baa"
      },
      "source": [
        "# Libraries \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "from keras.models import Model\n",
        "import csv\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def load_image(root_path, height, width, classes):\n",
        "    label_map = {'BacterialPneumonia': 1,\n",
        "                 'COVID-19': 0,\n",
        "                 'Normal': 2,\n",
        "                 'ViralPneumonia': 1}\n",
        "    data, labels = [], []\n",
        "    dirs = os.listdir(root_path)\n",
        "    \n",
        "    for d in dirs:\n",
        "        print(d)\n",
        "        path = os.path.join(root_path, d)\n",
        "        img_count = os.listdir(path)\n",
        "        for img in img_count:\n",
        "            try: \n",
        "                img_path = os.path.join(path, img)\n",
        "                image = cv2.imread(img_path)\n",
        "                image_from_array = Image.fromarray(image, 'RGB')\n",
        "                size_image = image_from_array.resize((width, height))\n",
        "                data.append(np.array(size_image))\n",
        "                labels.append(label_map[d])\n",
        "            except AttributeError:\n",
        "                print(\" \")\n",
        "    \n",
        "    Cells = np.array(data)\n",
        "    labels = np.array(labels)\n",
        "    \n",
        "    s = np.arange(Cells.shape[0])\n",
        "    np.random.seed(classes)\n",
        "    np.random.shuffle(s)\n",
        "    Cells = Cells[s]\n",
        "    labels = labels[s]\n",
        "    \n",
        "    X = Cells.astype('float32')/255\n",
        "    y = to_categorical(labels, classes)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def data_processing(data_path, height, width, classes):\n",
        "    train_path = os.path.join(data_path, 'NonAugmentedTrain')\n",
        "    val_path = os.path.join(data_path, 'ValData')\n",
        "    X_train, y_train = load_image(train_path, height, width, classes)\n",
        "    X_val, y_val = load_image(val_path, height, width, classes)\n",
        "    return X_train, y_train, X_val, y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4jJ3ET2kDSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras import backend as bk\n",
        "from keras import optimizers\n",
        "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras import initializers, regularizers\n",
        "import tensorflow as tf\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.models import load_model\n",
        "\n",
        "class Piecewise5(Activation):\n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(Piecewise5, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'Piecewise5'\n",
        "\n",
        "def get_flops(model):\n",
        "    run_meta = tf.RunMetadata()\n",
        "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
        "\n",
        "    # We use the Keras session graph in the call to the profiler.\n",
        "    flops = tf.profiler.profile(graph=bk.get_session().graph,\n",
        "                                run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "    return flops.total_float_ops\n",
        "\n",
        "\n",
        "def piecewise5(X):\n",
        "    return bk.switch(X < -0.6, (0.01 * X ),\n",
        "                     bk.switch(X < -0.2, (0.2 * X ),\n",
        "                               bk.switch(X < 0.2, (1 * X ),\n",
        "                                         bk.switch(X < 0.6, (1.5 * X ),\n",
        "                                                   bk.switch(X < 5, (3 * X ), (3 * X )))))) \n",
        "\n",
        "\n",
        "def custom_network(height, width, channels, classes, pre_trained=''):\n",
        "    weight_decay = 0.0001\n",
        "    input_img = Input(shape=(height, width, channels))\n",
        "    if pre_trained != '':\n",
        "        base_model = load_model(pre_trained)\n",
        "        num_layers = len(base_model.layers)\n",
        "        base_output = base_model.get_layer(index=num_layers-2).output\n",
        "        out = Dense(classes, activation='softmax')(base_output)\n",
        "        model = Model(inputs=base_model.input, outputs=out)\n",
        "    else:\n",
        "        conv_1 = Conv2D(64, (3, 3), padding='same', activation='piecewise5')(input_img)\n",
        "        block1_output = GlobalAveragePooling2D()(conv_1)\n",
        "        max_pool_1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv_1)\n",
        "        dropout_1 = Dropout(0.25)(max_pool_1)\n",
        "        \n",
        "        conv_2 = Conv2D(128, (3, 3), padding='same', activation='piecewise5')(dropout_1)\n",
        "        block2_output = GlobalAveragePooling2D()(conv_2)\n",
        "        max_pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv_2)\n",
        "        dropout_2 = Dropout(0.01)(max_pool_2)\n",
        "        \n",
        "        conv_3 = Conv2D(64, (3, 3), padding='same', activation='piecewise5')(dropout_2)\n",
        "        block3_output = GlobalAveragePooling2D()(conv_3)\n",
        "        max_pool_3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv_3)\n",
        "        dropout_3 = Dropout(0.01)(max_pool_3)\n",
        "        \n",
        "        conv_4 = Conv2D(128, (3, 3), padding='same', activation='piecewise5')(dropout_3)\n",
        "        block4_output = GlobalAveragePooling2D()(conv_4)\n",
        "        max_pool_4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv_4)\n",
        "        dropout_4 = Dropout(0.01)(max_pool_4)\n",
        "        \n",
        "        conv_5 = Conv2D(64, (3, 3), padding='same', activation='piecewise5')(dropout_4)\n",
        "        block5_output = GlobalAveragePooling2D()(conv_5)\n",
        "        max_pool_5 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv_5)\n",
        "        dropout_5 = Dropout(0.01)(max_pool_5)\n",
        "        \n",
        "        conv_6 = Conv2D(128, (3, 3), padding='same', activation='piecewise5')(dropout_5)\n",
        "        block6_output = GlobalAveragePooling2D()(conv_6)\n",
        "        \n",
        "        output = keras.layers.concatenate([block1_output, block2_output, \n",
        "                                           block3_output, block4_output, \n",
        "                                           block5_output, block6_output], \n",
        "                                          axis=1)\n",
        "        # output = Flatten()(output)\n",
        "        output = Dense(64, activation='piecewise5')(output)\n",
        "        out = Dense(classes, activation='softmax')(output)\n",
        "        \n",
        "        model = Model(inputs=input_img, outputs=out)\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgGc6UC_oL4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71d29048-c970-4248-f824-7333203e75f0"
      },
      "source": [
        "height = 400\n",
        "width = 300\n",
        "channels = 3\n",
        "classes = 3\n",
        "ratio_train = 0.8\n",
        "ratio_val = 0.2\n",
        "save_path = '/content/drive/My Drive/Colab Notebooks/training_info.xlsx'\n",
        "pre_trained_model_path = ''\n",
        "model_save_path = '/content/drive/My Drive/Colab Notebooks/test_model.h5'\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/covid19-detection-xray-dataset'\n",
        "    \n",
        "if ratio_train + ratio_val > 1:\n",
        "    print('Train/eval splitting failed')\n",
        "    exit(0)\n",
        "X_train, y_train, X_val, y_val = data_processing(data_path,\n",
        "                                                     height, \n",
        "                                                     width,  \n",
        "                                                     classes)\n",
        "        \n",
        "get_custom_objects().update({'piecewise5': Piecewise5(piecewise5)})\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
        "model = custom_network(height, width, channels, classes, pre_trained_model_path)\n",
        "    \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "epochs = 25\n",
        "hist1 = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_val, y_val))\n",
        "model.save(model_save_path)  # should end with .h5 or .hdf5\n",
        "    \n",
        "history = hist1.history\n",
        "    \n",
        "score = model.evaluate(X_val, y_val, verbose=0)\n",
        "score2 = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('Training loss:', score2[0])\n",
        "print('Training accuracy:', score2[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ViralPneumonia\n",
            "COVID-19\n",
            "Normal\n",
            "BacterialPneumonia\n",
            "BacterialPneumonia\n",
            "COVID-19\n",
            "Normal\n",
            "ViralPneumonia\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 400, 300, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 400, 300, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 200, 150, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 200, 150, 64) 0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 200, 150, 128 73856       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 100, 75, 128) 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100, 75, 128) 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 100, 75, 64)  73792       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 50, 38, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 50, 38, 64)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 50, 38, 128)  73856       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 25, 19, 128)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 25, 19, 128)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 25, 19, 64)   73792       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 13, 10, 64)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 13, 10, 64)   0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 13, 10, 128)  73856       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 64)           0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 128)          0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 64)           0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 128)          0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 64)           0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_6 (Glo (None, 128)          0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 576)          0           global_average_pooling2d_1[0][0] \n",
            "                                                                 global_average_pooling2d_2[0][0] \n",
            "                                                                 global_average_pooling2d_3[0][0] \n",
            "                                                                 global_average_pooling2d_4[0][0] \n",
            "                                                                 global_average_pooling2d_5[0][0] \n",
            "                                                                 global_average_pooling2d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           36928       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            195         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 408,067\n",
            "Trainable params: 408,067\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 2002 samples, validate on 988 samples\n",
            "Epoch 1/25\n",
            "2002/2002 [==============================] - 181s 90ms/step - loss: 2.2951 - accuracy: 0.5030 - val_loss: 0.8217 - val_accuracy: 0.5081\n",
            "Epoch 2/25\n",
            "2002/2002 [==============================] - 168s 84ms/step - loss: 0.7725 - accuracy: 0.5744 - val_loss: 0.6949 - val_accuracy: 0.6498\n",
            "Epoch 3/25\n",
            "2002/2002 [==============================] - 168s 84ms/step - loss: 0.7550 - accuracy: 0.6139 - val_loss: 0.6464 - val_accuracy: 0.6083\n",
            "Epoch 4/25\n",
            "2002/2002 [==============================] - 168s 84ms/step - loss: 0.6854 - accuracy: 0.7008 - val_loss: 0.6452 - val_accuracy: 0.6943\n",
            "Epoch 5/25\n",
            "2002/2002 [==============================] - 168s 84ms/step - loss: 0.6275 - accuracy: 0.7418 - val_loss: 0.8864 - val_accuracy: 0.6356\n",
            "Epoch 6/25\n",
            "2002/2002 [==============================] - 169s 85ms/step - loss: 0.5221 - accuracy: 0.7977 - val_loss: 0.5756 - val_accuracy: 0.7520\n",
            "Epoch 7/25\n",
            "2002/2002 [==============================] - 170s 85ms/step - loss: 0.4565 - accuracy: 0.8232 - val_loss: 1.2185 - val_accuracy: 0.6862\n",
            "Epoch 8/25\n",
            "2002/2002 [==============================] - 171s 85ms/step - loss: 0.3791 - accuracy: 0.8651 - val_loss: 1.0797 - val_accuracy: 0.6397\n",
            "Epoch 9/25\n",
            "2002/2002 [==============================] - 171s 85ms/step - loss: 0.3746 - accuracy: 0.8526 - val_loss: 0.5019 - val_accuracy: 0.8026\n",
            "Epoch 10/25\n",
            "2002/2002 [==============================] - 171s 85ms/step - loss: 0.3312 - accuracy: 0.8851 - val_loss: 0.6294 - val_accuracy: 0.7702\n",
            "Epoch 11/25\n",
            "2002/2002 [==============================] - 171s 85ms/step - loss: 0.3140 - accuracy: 0.8941 - val_loss: 0.7849 - val_accuracy: 0.6903\n",
            "Epoch 12/25\n",
            "2002/2002 [==============================] - 171s 85ms/step - loss: 0.2903 - accuracy: 0.8931 - val_loss: 1.3100 - val_accuracy: 0.5152\n",
            "Epoch 13/25\n",
            "2002/2002 [==============================] - 171s 86ms/step - loss: 0.2131 - accuracy: 0.9281 - val_loss: 0.3819 - val_accuracy: 0.8694\n",
            "Epoch 14/25\n",
            "2002/2002 [==============================] - 171s 86ms/step - loss: 0.1620 - accuracy: 0.9396 - val_loss: 0.4660 - val_accuracy: 0.8188\n",
            "Epoch 15/25\n",
            "2002/2002 [==============================] - 172s 86ms/step - loss: 0.1513 - accuracy: 0.9456 - val_loss: 0.8280 - val_accuracy: 0.7945\n",
            "Epoch 16/25\n",
            "2002/2002 [==============================] - 172s 86ms/step - loss: 0.1948 - accuracy: 0.9341 - val_loss: 0.8152 - val_accuracy: 0.6650\n",
            "Epoch 17/25\n",
            "2002/2002 [==============================] - 172s 86ms/step - loss: 0.1518 - accuracy: 0.9505 - val_loss: 0.3972 - val_accuracy: 0.8563\n",
            "Epoch 18/25\n",
            "2002/2002 [==============================] - 172s 86ms/step - loss: 0.1282 - accuracy: 0.9530 - val_loss: 0.7874 - val_accuracy: 0.7024\n",
            "Epoch 19/25\n",
            "2002/2002 [==============================] - 172s 86ms/step - loss: 0.1279 - accuracy: 0.9580 - val_loss: 0.7560 - val_accuracy: 0.7105\n",
            "Epoch 20/25\n",
            "2002/2002 [==============================] - 173s 86ms/step - loss: 0.1311 - accuracy: 0.9555 - val_loss: 0.6291 - val_accuracy: 0.7753\n",
            "Epoch 21/25\n",
            "2002/2002 [==============================] - 172s 86ms/step - loss: 0.1220 - accuracy: 0.9570 - val_loss: 0.3203 - val_accuracy: 0.8887\n",
            "Epoch 22/25\n",
            "2002/2002 [==============================] - 172s 86ms/step - loss: 0.1100 - accuracy: 0.9600 - val_loss: 0.6818 - val_accuracy: 0.7763\n",
            "Epoch 23/25\n",
            "2002/2002 [==============================] - 173s 86ms/step - loss: 0.1113 - accuracy: 0.9580 - val_loss: 1.0292 - val_accuracy: 0.7500\n",
            "Epoch 24/25\n",
            "2002/2002 [==============================] - 173s 86ms/step - loss: 0.0979 - accuracy: 0.9665 - val_loss: 0.7832 - val_accuracy: 0.7611\n",
            "Epoch 25/25\n",
            "2002/2002 [==============================] - 173s 86ms/step - loss: 0.0987 - accuracy: 0.9695 - val_loss: 0.2859 - val_accuracy: 0.8826\n",
            "Test loss: 0.285934246624047\n",
            "Test accuracy: 0.8825910687446594\n",
            "Training loss: 0.15833125246333313\n",
            "Training accuracy: 0.9400599598884583\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}